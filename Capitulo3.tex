\section{Introducción}

Vivimos en una era definida por la explosión de datos, comúnmente denominada la era del \textit{Big Data}. Campos tan diversos como la genómica, la astrofísica, las finanzas y las ciencias de la Tierra están generando volúmenes de información a una escala sin precedentes \cite{Sudmanns2019}. En particular, el sector de la salud y la observación geoespacial han emergido como dos de los dominios más prolíficos en la generación de datos complejos, como imágenes médicas de alta resolución y datos satelitales multiespectrales. El análisis de esta vasta cantidad de información es fundamental para la toma de decisiones críticas, desde el diagnóstico temprano de enfermedades hasta el monitoreo del cambio climático. Para enfrentar este desafío, han surgido tecnologías transformadoras como el cómputo en la nube, que proporciona la infraestructura escalable necesaria, y el aprendizaje profundo (\textit{deep learning}), que ofrece métodos potentes para extraer conocimiento de estos datos masivos \cite{Litjens2017}.

Sin embargo, la creciente especialización tecnológica ha llevado a una fragmentación significativa. Las organizaciones, tanto en el ámbito académico como en el industrial, desarrollan o adoptan sistemas de software altamente especializados, optimizados para tareas muy concretas. Si bien esta especialización es beneficiosa para resolver problemas específicos, a menudo conduce a la creación de ``silos de datos y procesamiento''. Estos silos son ecosistemas tecnológicos aislados que, aunque potentes individualmente, carecen de la capacidad de comunicarse e interactuar entre sí de manera fluida. Esta falta de interoperabilidad se ha convertido en uno de los desafíos más significativos de la ingeniería de software moderna en sistemas distribuidos \cite{Ondimu2017}. La heterogeneidad en lenguajes de programación, protocolos de comunicación y formatos de datos impide la creación de flujos de trabajo integrados, limitando el potencial científico y operativo que podría surgir de la combinación sinérgica de estas herramientas.

Para superar esta barrera, la industria ha adoptado el uso de \textit{middleware} como una solución estratégica. El \textit{middleware} actúa como un ``pegamento de software'', una capa de abstracción que se sitúa entre aplicaciones dispares y les permite comunicarse de manera estandarizada, ocultando la complejidad subyacente de la red y los sistemas operativos. En el contexto de la investigación científica, el \textit{middleware} es crucial para la construcción de flujos de trabajo científicos (\textit{scientific workflows}), que permiten automatizar y orquestar secuencias complejas de procesamiento y análisis de datos a través de múltiples sistemas distribuidos \cite{Goble2007}. Este enfoque no solo mejora la eficiencia y la reproducibilidad de la investigación, sino que también fomenta la colaboración al permitir que diferentes herramientas y servicios se combinen de formas novedosas.

\subsection{Definición del problema y justificación del proyecto}

En el Centro de Investigación y de Estudios Avanzados (CINVESTAV) Unidad Tamaulipas, el desafío de la interoperabilidad se manifiesta de manera concreta en la interacción (o la falta de ella) entre dos plataformas de software estratégicas. Por un lado, se encuentra \textbf{Nez}, un \textit{framework} avanzado para el procesamiento de datos a gran escala. \textit{Nez} no es solo una herramienta, sino la implementación del innovador modelo arquitectónico \textit{PuzzleMesh}, que concibe las aplicaciones como ``piezas de rompecabezas'' modulares y autocontenidas que pueden ser ensambladas para construir estructuras de procesamiento complejas y dinámicas. Esta arquitectura ha sido validada con éxito en dominios de alto impacto como el análisis de tomografías para diagnóstico médico y el procesamiento de imágenes satelitales para la observación de la Tierra.

La plataforma \textit{Nez} es, de hecho, un componente clave dentro de un ecosistema tecnológico más amplio y ambicioso denominado \textbf{Muyal-Ilal}, un servicio en la nube diseñado por investigadores de la Universidad Autónoma Metropolitana para la gestión, aseguramiento, intercambio y procesamiento de grandes volúmenes de datos, con un enfoque particular en el sector salud \cite{GonzalezCompean2020}. Dentro de este ecosistema, \textit{Nez} funciona como la plataforma de construcción de sistemas, guiando al personal de salud y de tecnologías de la información en la creación de flujos de trabajo de manera intuitiva, utilizando un enfoque de ``bloques de Lego'' para ensamblar herramientas de inteligencia artificial. Este ecosistema se complementa con otros servicios especializados como \textit{Muyal-Painal}, dedicado al almacenamiento y distribución de datos, y \textit{Muyal-Xelhua}, enfocado en la analítica de datos masivos. La filosofía de \textit{Nez} es, por tanto, facilitar la creación de sistemas complejos sin requerir conocimientos avanzados de programación, resolviendo dependencias tecnológicas a través de su arquitectura modular.

Por otro lado, se encuentra \textbf{Jub}, un concentrador y distribuidor de datos diseñado específicamente para el monitoreo de fenómenos atmosféricos, actuando como un punto central para la ingesta y distribución de flujos de datos en tiempo real. Adicionalmente, un tercer componente, \textit{MictlanX}, gestiona las operaciones de almacenamiento subyacentes para este ecosistema.

El problema central que aborda esta tesina es la ausencia de un mecanismo de comunicación nativo y estandarizado entre \textit{Nez} y \textit{Jub}. A pesar de sus capacidades evidentemente complementarias, estas dos plataformas operan en silos tecnológicos. Esta desconexión impone una barrera significativa: los usuarios de \textit{Jub} no pueden invocar de manera programática y automatizada las potentes capacidades de análisis y aprendizaje profundo de \textit{Nez}, y este último no puede ser alimentado directamente por los flujos de datos curados y distribuidos por \textit{Jub}. Este aislamiento tecnológico no solo representa una subutilización de los recursos existentes, sino que impide activamente la formación de una malla de servicios de ciencia de datos (\textit{Service Mesh}) cohesiva y eficiente, un paradigma arquitectónico moderno para gestionar la comunicación entre microservicios de manera fiable y segura \cite{Calcote2019}.

La justificación de este proyecto es, por tanto, clara y apremiante. El desarrollo de un \textit{middleware} que actúe como un puente de comunicación estandarizado es un paso indispensable para romper estos silos. Al permitir una integración transparente y ligera, este \textit{middleware} no solo conectará dos sistemas, sino que sentará las bases para una arquitectura de servicios distribuidos mucho más ambiciosa y escalable. Permitirá desbloquear nuevas y valiosas líneas de investigación y aplicación al combinar el análisis de datos atmosféricos con el procesamiento avanzado de imágenes y otras formas de análisis computacional. En resumen, este trabajo es un paso fundamental y estratégico para maximizar el valor y el impacto de los activos tecnológicos existentes en la institución, alineándolos con las mejores prácticas de la ingeniería de software contemporánea.

\subsection{Objetivo General}

Diseñar e implementar un \textit{middleware} de acoplamiento ligero que permita la interoperabilidad entre la plataforma \textit{Nez} y el concentrador de servicios \textit{Jub}, habilitando la creación de una malla de servicios de ciencia de datos y aprendizaje profundo para el procesamiento distribuido de datos e imágenes de distintos dominios.

\subsection{Objetivos Particulares}

\begin{itemize}
    \item Diseñar la arquitectura del \textit{middleware} para permitir la comunicación eficiente entre las plataformas \textit{Nez} y \textit{Jub}, basándose en principios de arquitecturas orientadas a servicios.
    \item Implementar el \textit{middleware} para lograr un acoplamiento ligero que habilite el intercambio de datos y la invocación de procesos en tiempo real.
    \item Integrar y validar el flujo de trabajo completo mediante la implementación de servicios de procesamiento distribuido de datos e imágenes, utilizando algoritmos de aprendizaje profundo.
    \item Mejorar las interfaces gráficas de usuario existentes en la plataforma \textit{Jub} para incorporar la nueva funcionalidad, facilitando la gestión y visualización de los datos procesados.
    \item Elaborar la documentación técnica detallada y los manuales de usuario del sistema para garantizar su correcto uso, mantenimiento y extensibilidad futura.
\end{itemize}

\subsection{Alcances y limitaciones del Proyecto}

El alcance de este proyecto se centra en la entrega de un prototipo funcional y bien documentado del \textit{middleware} de interoperabilidad. Este prototipo será capaz de recibir solicitudes desde \textit{Jub}, orquestar la ejecución de procesos de análisis en \textit{Nez} y gestionar el flujo de los resultados de vuelta al sistema de origen. El proyecto incluye la validación de la solución completa a través de un caso de uso específico de procesamiento de imágenes, así como las mejoras necesarias a la interfaz de usuario de \textit{Jub} para integrar esta nueva funcionalidad de manera intuitiva.

No obstante, el proyecto presenta las siguientes limitaciones en su fase actual:

\begin{itemize}
    \item El prototipo se validará con un conjunto limitado y bien definido de casos de uso, sin abarcar la totalidad de las capacidades potenciales de \textit{Nez} y \textit{Jub}.
    \item El manejo de errores en el \textit{middleware} se centrará en la notificación de fallos y el registro de eventos, sin implementar mecanismos avanzados de resiliencia como reintentos automáticos con retroceso exponencial (\textit{exponential backoff}) o patrones de \textit{circuit breaking}.
    \item La solución no incluirá una integración nativa con herramientas de monitoreo y observabilidad de nivel de producción, como \textit{Prometheus} para métricas o \textit{Grafana} para visualización, aunque su arquitectura permitirá dicha integración en el futuro.
    \item El modelo para consultar el estado de los trabajos de procesamiento se basará en un mecanismo de sondeo (\textit{polling}) iniciado por el cliente, en lugar de un sistema de notificaciones proactivas basadas en eventos (como \textit{webhooks}), que podría ser más eficiente en ciertos escenarios.
\end{itemize}

\subsection{Organización del Documento de Tesina}

Este documento se organiza en seis capítulos para presentar de manera clara, lógica y estructurada el desarrollo completo del proyecto. 

El \textbf{Capítulo 2} establece el \textbf{Marco Teórico}, donde se exploran y definen los conceptos fundamentales que sustentan este trabajo. Se abordan en profundidad temas como las arquitecturas de mallas de servicios (\textit{Service Mesh}), la teoría y práctica del \textit{middleware}, los desafíos de la interoperabilidad en sistemas heterogéneos, y se describen las tecnologías clave involucradas, con especial énfasis en el modelo conceptual \textit{PuzzleMesh} de la plataforma \textit{Nez}.

El \textbf{Capítulo 3} se dedica por completo al \textbf{Diseño Arquitectónico} del \textit{middleware}. En esta sección se detallan los requisitos funcionales y no funcionales, se justifican las decisiones de diseño cruciales, como la elección de un protocolo de comunicación personalizado implementado en Python como interfaz de comunicación, y se especifica formalmente el contrato de la API, incluyendo \textit{endpoints}, formatos de datos y códigos de estado.

El \textbf{Capítulo 4} describe la \textbf{Implementación} del prototipo. Este capítulo abarca la selección del \textit{stack} tecnológico (lenguajes, \textit{frameworks}), la estructura del código fuente, las decisiones de diseño a bajo nivel y las estrategias de empaquetado y despliegue mediante contenerización con \textit{Docker}.

En el \textbf{Capítulo 5} se presentan las \textbf{Pruebas y Validación} del sistema. Aquí se detalla el escenario de prueba configurado, se exponen los resultados de las pruebas de integración que demuestran la correcta comunicación entre \textit{Jub} y \textit{Nez}, y se realiza un análisis de rendimiento preliminar para evaluar la latencia y el \textit{throughput} del \textit{middleware}.

Finalmente, el \textbf{Capítulo 6} expone las \textbf{Conclusiones y el Trabajo Futuro}. En esta última sección se resumen las contribuciones más importantes del proyecto, se reflexiona sobre los resultados obtenidos y se delinean posibles líneas de investigación y desarrollo para extender y mejorar el trabajo realizado, como la implementación de mecanismos de seguridad más robustos o la integración con sistemas de orquestación avanzados.
